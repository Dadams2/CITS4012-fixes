
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>2. Dataset and DataLoader &#8212; CITS4012 Natural Language Processing</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Yelp Dataset at a glance" href="yelp_preprocessing.html" />
    <link rel="prev" title="1. Perceptron" href="perceptron.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo_ntlp.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">CITS4012 Natural Language Processing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   HOME
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basics/intro.html">
   Lab 01: Conda Environment and Python Refresher
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/installation.html">
     1. CITS4012 Base Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/installation_misc.html">
     2. CITS4012 MISC Enviornment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lab_machines.html">
     3. Use Lab Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/python_review.html">
     4. Python Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/iterables.html">
     5. Iterables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/numpy.html">
     6. Numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/matplotlib.html">
     7. Matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../NLTK/intro.html">
   Lab02: NLTK
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/start.html">
     1. Starting with NLTK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/closer_look.html">
     2. A Closer Look at Python: Texts as Lists of Words
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/computing.html">
     3. Computing with Language: Simple Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/take_control.html">
     4. Back to Python: Making Decisions and Taking Control
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/exercises.html">
     5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../spacy/intro.html">
   Lab03: spaCy NLP pipelines
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/container.html">
     1. Container Objects in spaCy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/pipeline.html">
     2. NLP Pipelines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/patterns.html">
     3. Finding Patterns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/telegram.html">
     4. Your first chatbot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/exercise.html">
     5. Exercise
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../gensim/intro.html">
   Lab04: Count-Based Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../gensim/tf-idf.html">
     1. TF-IDF in scikit-learn and Gensim
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gensim/classification.html">
     2. Document Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../nn/intro.html">
   Lab05: Introduction to Neural Networks and Pytorch
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/linear_model_numpy.html">
     1. Linear Models in Numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/tensors.html">
     2. Introduction to Pytorch Tensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/linear_model_pytorch.html">
     3. Linear Models in Pytorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../pytorch/intro.html">
   Lab06: Neural Network Building Blocks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/activations.html">
     1. Activation Functions and their derivatives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/loss.html">
     2. Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/computational_graph.html">
     3. Dynamic Computational Graph in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/nn_oop.html">
     4. Neural Networks in PyTorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../embeddings/intro.html">
   Lab07: Word Embeddings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/svd.html">
     1. Word Vectors from Word-Word Coocurrence Matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/glove.html">
     2. GloVe: Global Vectors for Word Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/word2vec.html">
     3. Word2Vec
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Lab08: Document Classification
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="perceptron.html">
     1. Perceptron
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     2. Dataset and DataLoader
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="yelp_preprocessing.html">
     3. Yelp Dataset at a glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="yelp.html">
     4. Yelp Review Dataset - Document Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../cnn/intro.html">
   Lab09: CNN for NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/dataset_frankenstein_processing.html">
     1. Frankenstein Dataset At a Glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/CBOW.html">
     2. Learning Embeddings with Continuous Bag of Words (CBOW)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/convolution.html">
     3. Convolution Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/dataset_AG_News_processing.html">
     4. AG News Dataset at A Glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/Document_Classification_with_CNN.html">
     5. Using CNN for Document Classification with Embeddings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://drive.google.com/file/d/1AQxhGLhoHE162HALo1NkgdaN-LVY4QWo/view?usp=sharing">
   data.zip
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/weiliu2k/CITS4012/raw/master/CITS4012LabBook.pdf">
   PDF
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/classification/data_prep.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/classification/data_prep.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset">
   2.1. Dataset
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#building-a-dataset-class-with-two-tensors">
     2.1.1. Building a
     <code class="docutils literal notranslate">
      <span class="pre">
       Dataset
      </span>
     </code>
     class with Two Tensors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#use-tensordataset">
     2.1.2. Use
     <code class="docutils literal notranslate">
      <span class="pre">
       TensorDataset
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataloader">
   2.2.
   <code class="docutils literal notranslate">
    <span class="pre">
     DataLoader
    </span>
   </code>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#putting-it-all-together">
   2.3. Putting it all together
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="dataset-and-dataloader">
<h1><span class="section-number">2. </span>Dataset and DataLoader<a class="headerlink" href="#dataset-and-dataloader" title="Permalink to this headline">¶</a></h1>
<div class="section" id="dataset">
<h2><span class="section-number">2.1. </span>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h2>
<p>In PyTorch, a dataset is represented by a regular Python class that inherits from
the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class. You can think of it as a list of tuples, each tuple corresponding to one data point (features, label).</p>
<p>The most fundamental methods it needs to implement are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__init__(self)</span></code>: it takes arguments needed to build a list of tuples, for example</p>
<ul>
<li><p>the name of a CSV file that will be loaded and processed; or</p></li>
<li><p>two tensors, one for features, another one for labels; or</p></li>
<li><p>or anything else, depending on the task at hand.</p></li>
</ul>
</li>
</ul>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>There is no need to load the whole dataset in the constructor
method (<code class="docutils literal notranslate"><span class="pre">__init__</span></code>). If your dataset is big (tens of thousands of
files, for instance), loading it at once would <strong>not</strong> be memory
efficient. It is recommended to load them on demand (whenever
<code class="docutils literal notranslate"><span class="pre">__get_item__</span></code> is called).</p>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__get_item__(self,</span> <span class="pre">index)</span></code>: this function allows the dataset to be indexed so that it can work like a list (<code class="docutils literal notranslate"><span class="pre">dataset[i]</span></code>)</p>
<ul>
<li><p>it must return a tuple (features, label) corresponding to the requested data point.</p></li>
<li><p>We can either return the corresponding slices of our pre-loaded dataset or, as mentioned above, load them on demand.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">__len__(self)</span></code>: it should simply return the size of the <em>whole dataset</em>. This is useful to ensure when sampling, the indexing is bouned by the size of the data.</p></li>
</ul>
<div class="section" id="building-a-dataset-class-with-two-tensors">
<h3><span class="section-number">2.1.1. </span>Building a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class with Two Tensors<a class="headerlink" href="#building-a-dataset-class-with-two-tensors" title="Permalink to this headline">¶</a></h3>
<p>Let’s build a simple custom dataset that takes two tensors as arguments: one for
the features, one for the labels.</p>
<p>Let’s first get the generated data from the <code class="docutils literal notranslate"><span class="pre">perceptron.ipynb</span></code> notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">import_ipynb</span>
<span class="kn">from</span> <span class="nn">perceptron</span> <span class="kn">import</span> <span class="n">get_toy_data</span>

<span class="n">data_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">x_data</span><span class="p">,</span> <span class="n">y_truth</span> <span class="o">=</span> <span class="n">get_toy_data</span><span class="p">(</span><span class="n">data_size</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="k">class</span> <span class="nc">CustomDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x_tensor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y_tensor</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Wait, is this a CPU tensor now? Why? Where is .to(device)?</span>
<span class="n">x_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">y_truth</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">CustomDataset</span><span class="p">(</span><span class="n">x_train_tensor</span><span class="p">,</span> <span class="n">y_train_tensor</span><span class="p">)</span>

<span class="c1"># Now we can iterate through our data points using simple indices</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([ 2.5058, -2.7603]), tensor(1.))
</pre></div>
</div>
</div>
</div>
<div class="admonition-why-do-we-not-sending-the-numpy-arrays-to-gpu admonition">
<p class="admonition-title">Why do we not sending the Numpy arrays to GPU?</p>
<p>We don’t want our whole training data to be loaded into GPU tensors, as we have been doing in our example so far, because it takes up space in our precious graphics card’s RAM.</p>
</div>
</div>
<div class="section" id="use-tensordataset">
<h3><span class="section-number">2.1.2. </span>Use <code class="docutils literal notranslate"><span class="pre">TensorDataset</span></code><a class="headerlink" href="#use-tensordataset" title="Permalink to this headline">¶</a></h3>
<div class="admonition-why-go-through-all-this-trouble-to-wrap-a-couple-of-tensors-in-a-class admonition">
<p class="admonition-title">Why go through all this trouble to wrap a couple of tensors in a class?</p>
<p>If the dataset is more than a couple of tensors, we can use PyTorch’s <code class="docutils literal notranslate"><span class="pre">TensorDataset</span></code> class, which
will do pretty much the same as our custom dataset above.</p>
</div>
<p>The full-fledged custom dataset class may seem like a stretch, but this is a design pattern that we will use repeatedly in later chapters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_train_tensor</span><span class="p">,</span> <span class="n">y_train_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([ 2.5058, -2.7603]), tensor(1.))
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="dataloader">
<h2><span class="section-number">2.2. </span><code class="docutils literal notranslate"><span class="pre">DataLoader</span></code><a class="headerlink" href="#dataloader" title="Permalink to this headline">¶</a></h2>
<p>Until now, we have used one data point training data at every training step. So we have been doing <strong>stochastic gradient descent</strong> all along. This is fine for small dataset, but if we want to go with large dataset, we must use <strong>mini-batch gradient descent</strong>. Thus, we need mini-batches. Thus, we need to slice our dataset accordingly. <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> saves us from doing it manually! All we need to do is to tell the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>:</p>
<ul class="simple">
<li><p>the dataset</p></li>
<li><p>the size of the mini-batch</p></li>
<li><p>whether we want to shuffle it or not</p></li>
</ul>
<div class="admonition-your-turn admonition">
<p class="admonition-title">Your Turn</p>
<p>Recall what’s <em>batch</em>, <em>mini-batch</em> and <em>stochastic</em> gradient decent.</p>
</div>
<p>A data loader will behave like an iterator, so we can loop over it and fetch a different
mini-batch every time.</p>
<div class="admonition-how-do-i-choose-my-mini-batch-size admonition">
<p class="admonition-title">How do I choose my mini-batch size?</p>
<p>It is typical to use powers of two for mini-batch sizes, like 16, 32, 64 or 128, and 32 or 64 are popular choices.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To retrieve a mini-batch, one can simply run the command below — it will return a list containing two tensors, one for the features, another one for the labels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[tensor([[ 3.6587, -1.7854],
         [ 1.2505, -2.9371],
         [ 3.3038,  2.9329],
         ...,
         [ 3.9159,  3.5062],
         [ 3.3351, -2.6869],
         [ 3.7338,  2.9684]]),
 tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
         0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1.,
         1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
         0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,
         0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
         0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
         0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,
         0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
         1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
         0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
         1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
         0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
         1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
         0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
         0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1.,
         0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
         1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,
         1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,
         1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
         0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
         0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
         0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
         0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
         0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,
         1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,
         1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,
         0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,
         0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
         1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,
         0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
         0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,
         1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,
         1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,
         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,
         0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
         0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
         0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,
         0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
         0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,
         1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
         0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,
         0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.,
         0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
         1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
         1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
         0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,
         0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
         1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
         1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
         0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
         0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,
         0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,
         1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,
         0., 1., 0., 0., 0., 0., 1., 0., 1., 0.])]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1
</pre></div>
</div>
</div>
</div>
<div class="admonition-to-shuffle-or-not-to-shuffle admonition">
<p class="admonition-title">To shuffle or not to shuffle</p>
<p>In the absolute majority of cases, you should set <code class="docutils literal notranslate"><span class="pre">shuffle=True</span></code> for your training set to improve the performance of gradient descent. There are a few exceptions, though, like time series problems, where shuffling actually leads to data leakage.</p>
<p>So, always ask yourself: “do I have a reason NOT to shuffle the data?”</p>
<p>“What about the validation and test sets?” There is no need to shuffle them since we are not computing gradients with them.</p>
</div>
<p>There is more to a DataLoader, for example, it is also possible to use it together with a <code class="docutils literal notranslate"><span class="pre">sampler</span></code> to fetch mini-batches that compensate for imbalanced classes, for instance.</p>
<div class="admonition-your-turn admonition">
<p class="admonition-title">Your Turn</p>
<p>Note we put all data in one “mini-batch” because we set <code class="docutils literal notranslate"><span class="pre">batch_size=1000</span></code>. Set <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> to a smaller number and observe the training time and performance.</p>
</div>
</div>
<div class="section" id="putting-it-all-together">
<h2><span class="section-number">2.3. </span>Putting it all together<a class="headerlink" href="#putting-it-all-together" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>A higher order function is a function returns a function, for example</p>
<p>The key elements of our training loop: <code class="docutils literal notranslate"><span class="pre">model</span></code>, <code class="docutils literal notranslate"><span class="pre">loss</span></code>, and <code class="docutils literal notranslate"><span class="pre">optimizer</span></code>. The actual training step function to be returned will have</p>
<ul class="simple">
<li><p>input: two arguments, namely, <em>features</em> and <em>labels</em>, and</p></li>
<li><p>return: the corresponding loss value.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_train_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="c1"># Builds function that performs a step in the train loop</span>
    <span class="k">def</span> <span class="nf">perform_train_step</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">):</span>
        <span class="c1"># Sets model to TRAIN mode</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Step 1 - Computes model&#39;s predictions - forward pass</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    
        <span class="c1"># Step 2 - Computes the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
        <span class="c1"># Step 3 - Computes gradients for parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># Step 4 - Updates parameters using gradients and</span>
        <span class="c1"># the learning rate</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># Returns the loss</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="c1"># Returns the function that will be called inside the</span>
    <span class="c1"># train loop</span>
    <span class="k">return</span> <span class="n">perform_train_step</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">import_ipynb</span>
<span class="kn">from</span> <span class="nn">perceptron</span> <span class="kn">import</span> <span class="n">Perceptron</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">60</span>

<span class="n">perceptron</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">input_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">perceptron</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">bce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
<span class="n">train_step</span> <span class="o">=</span> <span class="n">make_train_step</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">bce_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">change</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">last</span> <span class="o">=</span> <span class="mf">10.0</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="n">change</span> <span class="o">&gt;</span> <span class="n">epsilon</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="n">n_epochs</span> <span class="ow">or</span> <span class="n">last</span> <span class="o">&gt;</span> <span class="mf">0.3</span><span class="p">:</span>
<span class="c1"># For each epoch...</span>
<span class="c1"># for epoch in range(n_epochs):</span>
    <span class="c1"># inner loop</span>
    <span class="n">mini_batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span> 
        <span class="c1"># the dataset &quot;lives&quot; in the CPU, so do our mini-batches</span>
        <span class="c1"># therefore, we need to send those mini-batches to the</span>
        <span class="c1"># device where the model &quot;lives&quot;</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Performs one train step and returns the</span>
        <span class="c1"># corresponding loss for this mini-batch</span>
        
        <span class="n">mini_batch_loss</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
        <span class="n">mini_batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mini_batch_loss</span><span class="p">)</span>

    <span class="c1"># Computes average loss over all mini-batches</span>
    <span class="c1"># That&#39;s the epoch loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mini_batch_losses</span><span class="p">)</span>    
    <span class="n">change</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">last</span> <span class="o">-</span> <span class="n">loss</span><span class="p">)</span>    
    <span class="n">last</span> <span class="o">=</span> <span class="n">loss</span>
    <span class="n">epoch</span> <span class="o">+=</span> <span class="mi">1</span>    
    
<span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.10094598680734634
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">perceptron</span> <span class="o">=</span> <span class="n">perceptron</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">import_ipynb</span>
<span class="kn">from</span> <span class="nn">perceptron</span> <span class="kn">import</span> <span class="n">visualize_results</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">left_x</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">right_x</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">left_colors</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">right_colors</span> <span class="o">=</span>  <span class="p">[]</span>

<span class="c1"># Construct a stack of values and colors</span>
<span class="k">for</span> <span class="n">x_i</span><span class="p">,</span> <span class="n">y_true_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_truth</span><span class="p">):</span>
    <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span>

    <span class="k">if</span> <span class="n">y_true_i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">left_x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_i</span><span class="p">)</span>
        <span class="n">left_colors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">right_x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_i</span><span class="p">)</span>
        <span class="n">right_colors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>

<span class="n">left_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">left_x</span><span class="p">)</span>
<span class="n">right_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">right_x</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">left_x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">left_x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">right_x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">right_x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">visualize_results</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">y_truth</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(-0.3603001832962036, 6.013579845428467, -5.019380569458008, 5.617672443389893)
</pre></div>
</div>
<img alt="../_images/data_prep_22_1.png" src="../_images/data_prep_22_1.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "executablebooks/jupyter-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./classification"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="perceptron.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">1. </span>Perceptron</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="yelp_preprocessing.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">3. </span>Yelp Dataset at a glance</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By A/Prof. Wei Liu<br/>
        
            &copy; Copyright UWA 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>