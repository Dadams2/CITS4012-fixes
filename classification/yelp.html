
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Yelp Review Dataset - Document Classification &#8212; CITS4012 Natural Language Processing</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lab09: CNN for NLP" href="../cnn/intro.html" />
    <link rel="prev" title="3. Yelp Dataset at a glance" href="yelp_preprocessing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo_ntlp.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">CITS4012 Natural Language Processing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   HOME
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basics/intro.html">
   Lab 01: Conda Environment and Python Refresher
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/installation.html">
     1. CITS4012 Base Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/installation_misc.html">
     2. CITS4012 MISC Enviornment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lab_machines.html">
     3. Use Lab Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/python_review.html">
     4. Python Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/iterables.html">
     5. Iterables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/numpy.html">
     6. Numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/matplotlib.html">
     7. Matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../NLTK/intro.html">
   Lab02: NLTK
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/start.html">
     1. Starting with NLTK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/closer_look.html">
     2. A Closer Look at Python: Texts as Lists of Words
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/computing.html">
     3. Computing with Language: Simple Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/take_control.html">
     4. Back to Python: Making Decisions and Taking Control
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/exercises.html">
     5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../spacy/intro.html">
   Lab03: spaCy NLP pipelines
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/container.html">
     1. Container Objects in spaCy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/pipeline.html">
     2. NLP Pipelines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/patterns.html">
     3. Finding Patterns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/telegram.html">
     4. Your first chatbot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/exercise.html">
     5. Exercise
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../gensim/intro.html">
   Lab04: Count-Based Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../gensim/tf-idf.html">
     1. TF-IDF in scikit-learn and Gensim
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gensim/classification.html">
     2. Document Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../nn/intro.html">
   Lab05: Introduction to Neural Networks and Pytorch
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/linear_model_numpy.html">
     1. Linear Models in Numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/tensors.html">
     2. Introduction to Pytorch Tensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/linear_model_pytorch.html">
     3. Linear Models in Pytorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../pytorch/intro.html">
   Lab06: Neural Network Building Blocks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/activations.html">
     1. Activation Functions and their derivatives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/loss.html">
     2. Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/computational_graph.html">
     3. Dynamic Computational Graph in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/nn_oop.html">
     4. Neural Networks in PyTorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../embeddings/intro.html">
   Lab07: Word Embeddings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/svd.html">
     1. Word Vectors from Word-Word Coocurrence Matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/glove.html">
     2. GloVe: Global Vectors for Word Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/word2vec.html">
     3. Word2Vec
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Lab08: Document Classification
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="perceptron.html">
     1. Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="data_prep.html">
     2. Dataset and DataLoader
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="yelp_preprocessing.html">
     3. Yelp Dataset at a glance
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     4. Yelp Review Dataset - Document Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../cnn/intro.html">
   Lab09: CNN for NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/dataset_frankenstein_processing.html">
     1. Frankenstein Dataset At a Glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/CBOW.html">
     2. Learning Embeddings with Continuous Bag of Words (CBOW)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/convolution.html">
     3. Convolution Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/dataset_AG_News_processing.html">
     4. AG News Dataset at A Glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/Document_Classification_with_CNN.html">
     5. Using CNN for Document Classification with Embeddings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../rnn/intro.html">
   Lab10: RNN for NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/rnn.html">
     1. Recurrent Neural Networks - Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/elman_rnn_square.html">
     2. Classifying Synthetic Sequences - The Square Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/Surname_Dataset.html">
     3. Surname Dataset Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/Surname_Classification.html">
     4. Surname Classification with RNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://drive.google.com/file/d/1AQxhGLhoHE162HALo1NkgdaN-LVY4QWo/view?usp=sharing">
   data.zip
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/weiliu2k/CITS4012/raw/master/CITS4012LabBook.pdf">
   PDF
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/classification/yelp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/classification/yelp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-text-inputs-to-vectorized-minibatches">
   4.1. Converting Text Inputs to Vectorized Minibatches
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset">
     4.1.1. Dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-vocabulary-class">
     4.1.2. The
     <code class="docutils literal notranslate">
      <span class="pre">
       Vocabulary
      </span>
     </code>
     Class
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectorizer">
     4.1.3. Vectorizer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataloader">
     4.1.4. Dataloader
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-perceptron-classifier">
   4.2. A perceptron classifier
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training">
   4.3. Training
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initial-setup">
     4.3.1. Initial Setup
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-preparation">
     4.3.2. Training Preparation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     4.3.3. Training
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation-inference-and-inspection">
   4.4. Evaluation, Inference, and Inspection
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-on-test-data">
     4.4.1. EVALUATING ON TEST DATA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inference-and-classifying-new-data-points">
     4.4.2. INFERENCE AND CLASSIFYING NEW DATA POINTS
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspecting-model-weights">
     4.4.3. INSPECTING MODEL WEIGHTS
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#top-20-influential-words-in-positive-reviews">
       4.4.3.1. Top 20 Influential Words in Positive Reviews
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#top-20-influential-words-in-negative-reviews">
       4.4.3.2. Top 20 Influential Words in Negative Reviews
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-turn">
   4.5. Your Turn
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="yelp-review-dataset-document-classification">
<h1><span class="section-number">4. </span>Yelp Review Dataset - Document Classification<a class="headerlink" href="#yelp-review-dataset-document-classification" title="Permalink to this headline">¶</a></h1>
<div class="section" id="converting-text-inputs-to-vectorized-minibatches">
<h2><span class="section-number">4.1. </span>Converting Text Inputs to Vectorized Minibatches<a class="headerlink" href="#converting-text-inputs-to-vectorized-minibatches" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code>, the <code class="docutils literal notranslate"><span class="pre">Vectorizer</span></code>, and the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> are three classes to perform a crucial pipeline for PyTorch based NLP tasks: converting text inputs to vectorized minibatches. The pipeline starts with preprocessed text; each data point is a collection of tokens. In this example, the tokens happen to be words, but tokens can also be characters.</p>
<p>The three classes presented in this notebook are responsible for</p>
<ul class="simple">
<li><p>mapping each token to an integer to create a  <code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code>,</p></li>
<li><p>applying this mapping to each data point to create a vectorized form using <code class="docutils literal notranslate"><span class="pre">Vectorizer</span></code>, and</p></li>
<li><p>grouping the vectorized data points into a minibatch for the model through <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
</ul>
<div class="section" id="dataset">
<h3><span class="section-number">4.1.1. </span>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="k">class</span> <span class="nc">ReviewDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review_df</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">        review_df (pandas.DataFrame): the dataset</span>
<span class="sd">        vectorizer (ReviewVectorizer): vectorizer instantiated from dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_df</span> <span class="o">=</span> <span class="n">review_df</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_df</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;val&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_df</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;test&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_df</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lookup_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span><span class="p">),</span>
                            <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_size</span><span class="p">),</span>
                            <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load_dataset_and_make_vectorizer</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">review_csv</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load dataset and make a new vectorizer from scratch</span>
<span class="sd">        Args:</span>
<span class="sd">            review_csv (str): location of the dataset</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of ReviewDataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">review_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">review_csv</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">review_df</span><span class="p">,</span> <span class="n">ReviewVectorizer</span><span class="o">.</span><span class="n">from_dataframe</span><span class="p">(</span><span class="n">review_df</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">get_vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; returns the vectorizer &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span>
    <span class="k">def</span> <span class="nf">set_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; selects the splits in the dataset using a column in the dataframe</span>
<span class="sd">        Args:</span>
<span class="sd">        split (str): one of &quot;train&quot;, &quot;val&quot;, or &quot;test&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target_split</span> <span class="o">=</span> <span class="n">split</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lookup_dict</span><span class="p">[</span><span class="n">split</span><span class="p">]</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_size</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;the primary entry point method for PyTorch datasets</span>
<span class="sd">        Args:</span>
<span class="sd">        index (int): the index to the data point</span>
<span class="sd">        Returns:</span>
<span class="sd">        a dict of the data point&#39;s features (x_data) and label (y_target)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">row</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">review_vector</span> <span class="o">=</span> \
        <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">review</span><span class="p">)</span>
        <span class="n">rating_index</span> <span class="o">=</span> \
        <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span><span class="o">.</span><span class="n">rating_vocab</span><span class="o">.</span><span class="n">lookup_token</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">rating</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;x_data&#39;</span><span class="p">:</span> <span class="n">review_vector</span><span class="p">,</span>
                <span class="s1">&#39;y_target&#39;</span><span class="p">:</span> <span class="n">rating_index</span><span class="p">}</span>
    <span class="k">def</span> <span class="nf">get_num_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Given a batch size, return the number of batches in the dataset</span>
<span class="sd">        Args:</span>
<span class="sd">        batch_size (int)</span>
<span class="sd">        Returns:</span>
<span class="sd">        number of batches in the dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="the-vocabulary-class">
<h3><span class="section-number">4.1.2. </span>The <code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code> Class<a class="headerlink" href="#the-vocabulary-class" title="Permalink to this headline">¶</a></h3>
<p>The first stage to map each token to a numerical version of itself. The standard methodology is to have a bijection - a mapping that can be reversed between the tokens and integers. In Python, this is simply two dictionaries.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Vocabulary</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Class to process text and extract Vocabulary for mapping&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_to_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add_unk</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;UNK&gt;&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            token_to_idx (dict): a pre-existingmap of tokens to indices</span>
<span class="sd">            add_unk (bool): a flag that indicates whether to add the UNK token</span>
<span class="sd">            unk_token (str): the UNK token to add into the Vocabulary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token_to_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">token_to_idx</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span> <span class="o">=</span> <span class="n">token_to_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span> <span class="o">=</span> <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">token</span> 
                                <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_add_unk</span> <span class="o">=</span> <span class="n">add_unk</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_unk_token</span> <span class="o">=</span> <span class="n">unk_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">add_unk</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="n">unk_token</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_serializable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; returns a dictionary that can be serialized &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;token_to_idx&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">,</span>
                <span class="s1">&#39;add_unk&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_unk</span><span class="p">,</span>
                <span class="s1">&#39;unk_token&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unk_token</span><span class="p">}</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_serializable</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">contents</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; instantiates the Vocabulary from a serialized dictionary &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">contents</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">add_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update mapping dicts based on the token.</span>
<span class="sd">        Args:</span>
<span class="sd">            token (str): the item to add into the Vocabulary</span>
<span class="sd">        Returns:</span>
<span class="sd">            index (int): the integer corresponding to the token</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">token</span>
        <span class="k">return</span> <span class="n">index</span>
    <span class="k">def</span> <span class="nf">lookup_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieve the index associated with the token</span>
<span class="sd">        or the UNK index if token isn&#39;t present.</span>
<span class="sd">        Args:</span>
<span class="sd">            token (str): the token to look up</span>
<span class="sd">        Returns:</span>
<span class="sd">            index (int): the index corresponding to the token</span>
<span class="sd">        Notes:</span>
<span class="sd">            `unk_index` needs to be &gt;=0 (having been added into the Vocabulary)</span>
<span class="sd">            for the UNK functionality</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_unk</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
    <span class="k">def</span> <span class="nf">lookup_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the token associated with the index</span>
<span class="sd">        Args:</span>
<span class="sd">            index (int): the index to look up</span>
<span class="sd">        Returns:</span>
<span class="sd">            token (str): the token corresponding to the index</span>
<span class="sd">        Raises:</span>
<span class="sd">        KeyError: if the index is not in the Vocabulary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">index</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;the index (</span><span class="si">%d</span><span class="s2">) is not in the Vocabulary&quot;</span> <span class="o">%</span> <span class="n">index</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;Vocabulary(size=</span><span class="si">%d</span><span class="s2">)&gt;&quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="vectorizer">
<h3><span class="section-number">4.1.3. </span>Vectorizer<a class="headerlink" href="#vectorizer" title="Permalink to this headline">¶</a></h3>
<p>The second stage of going from a text dataset to a vectorized minibatch is to iterate through the tokens of an input data point and convert each token to its integer form. The result of this iteration should be a vector. Because this vector will be combined with vectors from other data points, there is a constraint that the vectors produced by the Vectorizer should always have the same length.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="k">class</span> <span class="nc">ReviewVectorizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; The Vectorizer which coordinates the Vocabularies and puts them to use&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review_vocab</span><span class="p">,</span> <span class="n">rating_vocab</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            review_vocab (Vocabulary): maps words to integers</span>
<span class="sd">            rating_vocab (Vocabulary): maps class labels to integers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span> <span class="o">=</span> <span class="n">review_vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rating_vocab</span> <span class="o">=</span> <span class="n">rating_vocab</span>
    <span class="k">def</span> <span class="nf">vectorize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a collapsed one hot vector for the review</span>
<span class="sd">        Args:</span>
<span class="sd">            review (str): the review</span>
<span class="sd">        Returns:</span>
<span class="sd">            one_hot (np.ndarray): the collapsed onehot encoding</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">one_hot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">:</span>
                <span class="n">one_hot</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="o">.</span><span class="n">lookup_token</span><span class="p">(</span><span class="n">token</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">one_hot</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_dataframe</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">review_df</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiate the vectorizer from the dataset dataframe</span>
<span class="sd">        Args:</span>
<span class="sd">            review_df (pandas.DataFrame): the review dataset</span>
<span class="sd">            cutoff (int): the parameter for frequency based filtering</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of the ReviewVectorizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">review_vocab</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">(</span><span class="n">add_unk</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">rating_vocab</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">(</span><span class="n">add_unk</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># Add ratings</span>
        <span class="k">for</span> <span class="n">rating</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">review_df</span><span class="o">.</span><span class="n">rating</span><span class="p">)):</span>
            <span class="n">rating_vocab</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="n">rating</span><span class="p">)</span>
        <span class="c1"># Add top words if count &gt; provided count</span>
        <span class="n">word_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">review_df</span><span class="o">.</span><span class="n">review</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">:</span>
                    <span class="n">word_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="n">cutoff</span><span class="p">:</span>
                <span class="n">review_vocab</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">review_vocab</span><span class="p">,</span> <span class="n">rating_vocab</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_serializable</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">contents</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Intantiate a ReviewVectorizer from a serializable dictionary</span>
<span class="sd">        Args:</span>
<span class="sd">            contents (dict): the serializable dictionary</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of the ReviewVectorizer class</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">review_vocab</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="o">.</span><span class="n">from_serializable</span><span class="p">(</span><span class="n">contents</span><span class="p">[</span><span class="s1">&#39;review_vocab&#39;</span><span class="p">])</span>
        <span class="n">rating_vocab</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="o">.</span><span class="n">from_serializable</span><span class="p">(</span><span class="n">contents</span><span class="p">[</span><span class="s1">&#39;rating_vocab&#39;</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">review_vocab</span><span class="o">=</span><span class="n">review_vocab</span><span class="p">,</span> <span class="n">rating_vocab</span><span class="o">=</span><span class="n">rating_vocab</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_serializable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create the serializable dictionary for caching</span>
<span class="sd">        Returns:</span>
<span class="sd">            contents (dict): the serializable dictionary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;review_vocab&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="o">.</span><span class="n">to_serializable</span><span class="p">(),</span>
                <span class="s1">&#39;rating_vocab&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rating_vocab</span><span class="o">.</span><span class="n">to_serializable</span><span class="p">()}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="dataloader">
<h3><span class="section-number">4.1.4. </span>Dataloader<a class="headerlink" href="#dataloader" title="Permalink to this headline">¶</a></h3>
<p>The final stage of the text to vectorized minibatch pipeline is to actually group the vectorized data
points.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="k">def</span> <span class="nf">generate_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A generator function which wraps the PyTorch DataLoader. It will</span>
<span class="sd">    ensure each tensor is on the write device location.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                            <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">data_dict</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">out_data_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">out_data_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">out_data_dict</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="a-perceptron-classifier">
<h2><span class="section-number">4.2. </span>A perceptron classifier<a class="headerlink" href="#a-perceptron-classifier" title="Permalink to this headline">¶</a></h2>
<p>This is a simple one hidden layer Perceptron that we have seen many times by now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="k">class</span> <span class="nc">ReviewClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; a simple perceptron-based classifier &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            num_features (int): the size of the input feature vector</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ReviewClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">num_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">,</span> <span class="n">apply_sigmoid</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The forward pass of the classifier</span>
<span class="sd">        Args:</span>
<span class="sd">            x_in (torch.Tensor): an input data tensor </span>
<span class="sd">                    x_in.shape should be (batch, num_features)</span>
<span class="sd">            apply_sigmoid (bool): a flag for the sigmoid activation</span>
<span class="sd">                    should be false if used with the cross-entropy losses</span>
<span class="sd">        Returns:</span>
<span class="sd">            the resulting tensor. tensor.shape should be (batch,).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">apply_sigmoid</span><span class="p">:</span>
            <span class="n">y_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y_out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y_out</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training">
<h2><span class="section-number">4.3. </span>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h2>
<div class="section" id="initial-setup">
<h3><span class="section-number">4.3.1. </span>Initial Setup<a class="headerlink" href="#initial-setup" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="c1"># Data and path information</span>
    <span class="n">frequency_cutoff</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
    <span class="n">model_state_file</span><span class="o">=</span><span class="s1">&#39;model.pth&#39;</span><span class="p">,</span>
    <span class="n">review_csv</span><span class="o">=</span><span class="s1">&#39;../data/yelp/reviews_with_splits_full.csv&#39;</span><span class="p">,</span>
    <span class="n">save_dir</span><span class="o">=</span><span class="s1">&#39;model_storage/yelp/&#39;</span><span class="p">,</span>
    <span class="n">vectorizer_file</span><span class="o">=</span><span class="s1">&#39;vectorizer.json&#39;</span><span class="p">,</span>
    <span class="c1"># No model hyperparameters</span>
    <span class="c1"># Training hyperparameters</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">early_stopping_criteria</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1337</span><span class="p">,</span>
    <span class="c1"># Runtime options</span>
    <span class="n">cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training-preparation">
<h3><span class="section-number">4.3.2. </span>Training Preparation<a class="headerlink" href="#training-preparation" title="Permalink to this headline">¶</a></h3>
<p>Recall that three key components that we need prepare for a training are:</p>
<ul class="simple">
<li><p>model</p></li>
<li><p>loss function</p></li>
<li><p>optimizer</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">make_train_state</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;epoch_index&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;train_acc&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;val_acc&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>

<span class="n">train_state</span> <span class="o">=</span> <span class="n">make_train_state</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">args</span><span class="o">.</span><span class="n">cuda</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># dataset and vectorizer</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ReviewDataset</span><span class="o">.</span><span class="n">load_dataset_and_make_vectorizer</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">review_csv</span><span class="p">)</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_vectorizer</span><span class="p">()</span>
<span class="c1"># model</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">ReviewClassifier</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">))</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># loss and optimizer</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_target</span><span class="p">):</span>
    <span class="n">y_target</span> <span class="o">=</span> <span class="n">y_target</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    <span class="n">y_pred_indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="c1">#.max(dim=1)[1]</span>
    <span class="n">n_correct</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y_pred_indices</span><span class="p">,</span> <span class="n">y_target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">n_correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_pred_indices</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id1">
<h3><span class="section-number">4.3.3. </span>Training<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>This is the most time-consuming cell. Training on a NVIDIA RTX3070 GPU with the full dataset took 9237.4 seconds (rougly 3 hours). You should changes the <code class="docutils literal notranslate"><span class="pre">args</span></code> settings to use the LITE dataset first with a reduced number of epochs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="mf">9237.4</span><span class="o">/</span><span class="mi">60</span><span class="o">/</span><span class="mi">60</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.5659444444444444
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">for</span> <span class="n">epoch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;epoch_index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_index</span>
    <span class="c1"># Iterate over training dataset</span>
    <span class="c1"># setup: batch generator, set loss and acc to 0, set train mode on</span>
    <span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="n">batch_generator</span> <span class="o">=</span> <span class="n">generate_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">running_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">classifier</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">):</span>
        <span class="c1"># the training routine is 5 steps:</span>
        <span class="c1"># step 1. zero the gradients</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># step 2. compute the output</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">x_in</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="c1"># step 3. compute the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">loss_batch</span><span class="o">-</span><span class="n">running_loss</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># step 4. use loss to produce gradients</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># step 5. use optimizer to take gradient step</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># compute the accuracy</span>
        <span class="n">acc_batch</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">])</span>
        <span class="n">running_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">acc_batch</span> <span class="o">-</span> <span class="n">running_acc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span><span class="p">)</span>
    <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;train_acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_acc</span><span class="p">)</span>

    <span class="c1"># Iterate over val dataset</span>
    <span class="c1"># setup: batch generator, set loss and acc to 0, set eval mode on</span>
    <span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">)</span>
    <span class="n">batch_generator</span> <span class="o">=</span> <span class="n">generate_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="n">running_acc</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="n">classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">):</span>
        <span class="c1"># step 1. compute the output</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">x_in</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="c1"># step 2. compute the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">loss_batch</span> <span class="o">-</span> <span class="n">running_loss</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># step 3. compute the accuracy</span>
        <span class="n">acc_batch</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">])</span>
        <span class="n">running_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">acc_batch</span> <span class="o">-</span> <span class="n">running_acc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span><span class="p">)</span>
    <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="evaluation-inference-and-inspection">
<h2><span class="section-number">4.4. </span>Evaluation, Inference, and Inspection<a class="headerlink" href="#evaluation-inference-and-inspection" title="Permalink to this headline">¶</a></h2>
<p>After you have a trained model, the next steps are to either evaluate how it did against some heldout
portion of the data, use it to do inference on new data, or inspect the model weights to see what it is has learned. In this section, we will show you all three steps.</p>
<div class="section" id="evaluating-on-test-data">
<h3><span class="section-number">4.4.1. </span>EVALUATING ON TEST DATA<a class="headerlink" href="#evaluating-on-test-data" title="Permalink to this headline">¶</a></h3>
<p>To evaluate the data on the heldout test set, the code is exactly the same as the validation loop in the training routine we saw in the previous example, but with one minor difference: the split is set to be ‘test’ rather than ‘val’. The difference between the two partitions of the dataset comes from the fact that the test set should be run as little as possible. Each time you run a trained model on the test set, make a new model decision (such as changing the size of the layers), and remeasure the new retrained model on the test set, you are biasing your modeling decisions toward the test data. In other words, if you repeat that process often enough, the test set will become meaningless as an accurate measure of truly heldout data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">batch_generator</span> <span class="o">=</span> <span class="n">generate_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">running_acc</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">):</span>
    <span class="c1"># compute the output</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">x_in</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
    <span class="c1"># compute the loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
    <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">running_loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">loss_batch</span> <span class="o">-</span> <span class="n">running_loss</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># compute the accuracy</span>
    <span class="n">acc_batch</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">])</span>
    <span class="n">running_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">acc_batch</span> <span class="o">-</span> <span class="n">running_acc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;test_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">running_loss</span>
<span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;test_acc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">running_acc</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test loss: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;test_loss&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;test_acc&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.243
Test Accuracy: 92.45
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="inference-and-classifying-new-data-points">
<h3><span class="section-number">4.4.2. </span>INFERENCE AND CLASSIFYING NEW DATA POINTS<a class="headerlink" href="#inference-and-classifying-new-data-points" title="Permalink to this headline">¶</a></h3>
<p>Another method for evaluating the model is to do inference on new data and make qualitative judgments about whether the model is working.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="c1"># Preprocess the reviews</span>
<span class="k">def</span> <span class="nf">preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">==</span> <span class="nb">float</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;([.,!?])&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot; \1 &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^a-zA-Z.,!?]+&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>

<span class="k">def</span> <span class="nf">predict_rating</span><span class="p">(</span><span class="n">review</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span><span class="n">decision_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predict the rating of a review</span>
<span class="sd">    Args:</span>
<span class="sd">        review (str): the text of the review</span>
<span class="sd">        classifier (ReviewClassifier): the trained model</span>
<span class="sd">        vectorizer (ReviewVectorizer): the corresponding vectorizer</span>
<span class="sd">        decision_threshold (float): The numerical boundary which</span>
<span class="sd">                                    separates the rating classes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">review</span> <span class="o">=</span> <span class="n">preprocess_text</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>
    <span class="n">vectorized_review</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">review</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">vectorized_review</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">probability_value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">index</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">probability_value</span> <span class="o">&lt;</span> <span class="n">decision_threshold</span><span class="p">:</span>
        <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">rating_vocab</span><span class="o">.</span><span class="n">lookup_index</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_review</span> <span class="o">=</span> <span class="s2">&quot;NLP is pretty awesome&quot;</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">predict_rating</span><span class="p">(</span><span class="n">test_review</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> &gt; </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_review</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NLP is pretty awesome &gt; positive
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="inspecting-model-weights">
<h3><span class="section-number">4.4.3. </span>INSPECTING MODEL WEIGHTS<a class="headerlink" href="#inspecting-model-weights" title="Permalink to this headline">¶</a></h3>
<p>Finally, the last way to understand whether a model is doing well after it has finished training is to inspect the weights and make qualitative judgments about whether they seem correct.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sort weights</span>
<span class="n">fc1_weights</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">fc1_weights</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="top-20-influential-words-in-positive-reviews">
<h4><span class="section-number">4.4.3.1. </span>Top 20 Influential Words in Positive Reviews<a class="headerlink" href="#top-20-influential-words-in-positive-reviews" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Top 20 words</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Influential words in Positive Reviews:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">review_vocab</span><span class="o">.</span><span class="n">lookup_index</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Influential words in Positive Reviews:

pastys
excellentes
mmmmmmmm
yummo
teau
excellents
reina
besten
nhats
soulful
bovine
nsupport
bottling
abel
emplacement
recyclable
couleurs
kouign
whimsy
couverte
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="top-20-influential-words-in-negative-reviews">
<h4><span class="section-number">4.4.3.2. </span>Top 20 Influential Words in Negative Reviews<a class="headerlink" href="#top-20-influential-words-in-negative-reviews" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Top 20 negative words</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Influential words in Negative Reviews:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">indices</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">review_vocab</span><span class="o">.</span><span class="n">lookup_index</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Influential words in Negative Reviews:

ception
nlame
nworse
nnasty
discusting
discriminates
ewwwww
disputing
crook
demerits
acrid
scab
nyuck
nbland
dishonesty
unfresh
lecturing
poorest
grossest
condescendingly
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="your-turn">
<h2><span class="section-number">4.5. </span>Your Turn<a class="headerlink" href="#your-turn" title="Permalink to this headline">¶</a></h2>
<div class="admonition-your-turn admonition">
<p class="admonition-title">Your Turn</p>
<p>Modify the vectorizer to use Word Embeddings (e.g. GloVe) to replace one-hot encoding. Observe the performance change. You may need to handle unknown words.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "executablebooks/jupyter-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./classification"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="yelp_preprocessing.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">3. </span>Yelp Dataset at a glance</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="../cnn/intro.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Lab09: CNN for NLP</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By A/Prof. Wei Liu<br/>
        
            &copy; Copyright UWA 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>