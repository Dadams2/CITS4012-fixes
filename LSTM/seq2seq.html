
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Sequence to Sequence Models &#8212; CITS4012 Natural Language Processing</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Surname Generation - Unconditioned" href="Surname_Generation_Unconditioned.html" />
    <link rel="prev" title="3. The Square Model Using GRU and LSTM" href="gru_lstm_square.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo_ntlp.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">CITS4012 Natural Language Processing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   HOME
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basics/intro.html">
   Lab 01: Conda Environment and Python Refresher
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/installation.html">
     1. CITS4012 Base Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/installation_misc.html">
     2. CITS4012 MISC Enviornment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lab_machines.html">
     3. Use Lab Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/python_review.html">
     4. Python Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/iterables.html">
     5. Iterables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/numpy.html">
     6. Numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/matplotlib.html">
     7. Matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../NLTK/intro.html">
   Lab02: NLTK
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/start.html">
     1. Starting with NLTK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/closer_look.html">
     2. A Closer Look at Python: Texts as Lists of Words
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/computing.html">
     3. Computing with Language: Simple Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/take_control.html">
     4. Back to Python: Making Decisions and Taking Control
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/exercises.html">
     5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../spacy/intro.html">
   Lab03: spaCy NLP pipelines
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/container.html">
     1. Container Objects in spaCy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/pipeline.html">
     2. NLP Pipelines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/patterns.html">
     3. Finding Patterns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/telegram.html">
     4. Your first chatbot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/exercise.html">
     5. Exercise
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../gensim/intro.html">
   Lab04: Count-Based Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../gensim/tf-idf.html">
     1. TF-IDF in scikit-learn and Gensim
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gensim/classification.html">
     2. Document Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../nn/intro.html">
   Lab05: Introduction to Neural Networks and Pytorch
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/linear_model_numpy.html">
     1. Linear Models in Numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/tensors.html">
     2. Introduction to Pytorch Tensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/linear_model_pytorch.html">
     3. Linear Models in Pytorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../pytorch/intro.html">
   Lab06: Neural Network Building Blocks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/activations.html">
     1. Activation Functions and their derivatives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/loss.html">
     2. Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/computational_graph.html">
     3. Dynamic Computational Graph in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/nn_oop.html">
     4. Neural Networks in PyTorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../embeddings/intro.html">
   Lab07: Word Embeddings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/svd.html">
     1. Word Vectors from Word-Word Coocurrence Matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/glove.html">
     2. GloVe: Global Vectors for Word Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/word2vec.html">
     3. Word2Vec
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../classification/intro.html">
   Lab08: Document Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/perceptron.html">
     1. Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/data_prep.html">
     2. Dataset and DataLoader
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/yelp_preprocessing.html">
     3. Yelp Dataset at a glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/yelp.html">
     4. Yelp Review Dataset - Document Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../cnn/intro.html">
   Lab09: CNN for NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/dataset_frankenstein_processing.html">
     1. Frankenstein Dataset At a Glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/CBOW.html">
     2. Learning Embeddings with Continuous Bag of Words (CBOW)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/convolution.html">
     3. Convolution Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/dataset_AG_News_processing.html">
     4. AG News Dataset at A Glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/Document_Classification_with_CNN.html">
     5. Using CNN for Document Classification with Embeddings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../rnn/intro.html">
   Lab10: RNN for NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/rnn.html">
     1. Recurrent Neural Networks - Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/elman_rnn_square.html">
     2. Classifying Synthetic Sequences - The Square Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/Surname_Dataset.html">
     3. Surname Dataset Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/Surname_Classification.html">
     4. Surname Classification with RNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Lab11: GRU, LSTM and Seq2Seq
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="gru.html">
     1. Gated Recurrent Units (GRUs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lstm.html">
     2. Long Short Term Memories (LSTMs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="gru_lstm_square.html">
     3. The Square Model Using GRU and LSTM
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     4. Sequence to Sequence Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Surname_Generation_Unconditioned.html">
     5. Surname Generation - Unconditioned
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Surname_Generation_Conditioned.html">
     6. Surname Generation Conditioned
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../attention/intro.html">
   Lab12: Sequence to Sequence Learning with Attention
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../attention/attention.html">
     1. Attention Mechanism
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../attention/self_attention.html">
     2. Self-Attention
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../attention/nmt_data_processing.html">
     3. Neual Machine Translation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../attention/PackedSequence.html">
     4. Packed Sequences
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../attention/NMT_No_Sampling.html">
     5. Neural Machine Translation - No Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../attention/NMT_scheduled_sampling.html">
     6. Neural Machine Translation - Scheduled Sampling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../transformer/intro.html">
   Extra: Transformers
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../transformer/position_encoding.html">
     1. Positional Encoding
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../transformer/LayerNorm.html">
     2. Layer Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../transformer/transformer.html">
     3. Transform and Roll Out
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://drive.google.com/file/d/1AQxhGLhoHE162HALo1NkgdaN-LVY4QWo/view?usp=sharing">
   data.zip
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/weiliu2k/CITS4012/raw/master/CITS4012LabBook.pdf">
   PDF
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/LSTM/seq2seq.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/LSTM/seq2seq.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-plotting-and-helper-functions">
   4.1. Download Plotting and Helper Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   4.2. Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-generation">
   4.3. Data Generation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encoder-decoder-architecture">
   4.4. Encoder-Decoder Architecture
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encoder">
     4.4.1. Encoder
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decoder">
     4.4.2. Decoder
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#teacher-forcing">
       4.4.2.1. Teacher Forcing
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encoder-decoder">
     4.4.3. Encoder + Decoder
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-preparation">
     4.4.4. Data Preparation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-training-configuration">
     4.4.5. Model Training &amp; Configuration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualizing-predictions">
     4.4.6. Visualizing Predictions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bidirectional-lstm-as-an-encoder">
   4.5. Bidirectional LSTM as an Encoder
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="sequence-to-sequence-models">
<h1><span class="section-number">4. </span>Sequence to Sequence Models<a class="headerlink" href="#sequence-to-sequence-models" title="Permalink to this headline">¶</a></h1>
<p>In this notebook, we will be using the same squares as before, but this time know the first two corners (the source sequence) and ask our model to predict the next two corners (the target sequence). As with every sequence-related problem, the order is important, so it is not enough to get the corner’s coordinates right, but they should follow the same direction (clockwise or counter-clockwise).</p>
<div class="section" id="download-plotting-and-helper-functions">
<h2><span class="section-number">4.1. </span>Download Plotting and Helper Functions<a class="headerlink" href="#download-plotting-and-helper-functions" title="Permalink to this headline">¶</a></h2>
<p>Download the followings files and place them in the same folder as the notebook before proceed further. These files contain the utility functions and plotting functions needed for this notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">FileLink</span><span class="p">,</span> <span class="n">FileLinks</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FileLink</span><span class="p">(</span><span class="s1">&#39;plots.py&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><a href='plots.py' target='_blank'>plots.py</a><br></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FileLink</span><span class="p">(</span><span class="s1">&#39;plots_seq2seq.py&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><a href='plots_seq2seq.py' target='_blank'>plots_seq2seq.py</a><br></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FileLink</span><span class="p">(</span><span class="s1">&#39;util.py&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><a href='util.py' target='_blank'>util.py</a><br></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FileLink</span><span class="p">(</span><span class="s1">&#39;replay.py&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><a href='replay.py' target='_blank'>replay.py</a><br></div></div>
</div>
</div>
<div class="section" id="imports">
<h2><span class="section-number">4.2. </span>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">random_split</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">from</span> <span class="nn">util</span> <span class="kn">import</span> <span class="n">StepByStep</span>
<span class="kn">from</span> <span class="nn">plots</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">plots_seq2seq</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-generation">
<h2><span class="section-number">4.3. </span>Data Generation<a class="headerlink" href="#data-generation" title="Permalink to this headline">¶</a></h2>
<p>Same method as before for generating noisy squares.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_sequences</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">variable_len</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">13</span><span class="p">):</span>
    <span class="n">basic_corners</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">bases</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">variable_len</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">n</span>
    <span class="n">directions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">basic_corners</span><span class="p">[[(</span><span class="n">b</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="mi">4</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]][</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">d</span><span class="o">*</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span><span class="p">)][:</span><span class="n">l</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span> <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bases</span><span class="p">,</span> <span class="n">directions</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">points</span><span class="p">,</span> <span class="n">directions</span>
</pre></div>
</div>
</div>
</div>
<p>Visualise an counter clock-wise perfect square and a clock-wise one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">counter_vs_clock</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/seq2seq_13_0.png" src="../_images/seq2seq_13_0.png" />
</div>
</div>
<p>Since there are four corners to start from and two directions to follow, there are effectively eight possible sequences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plot_sequences</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">target_len</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/seq2seq_15_0.png" src="../_images/seq2seq_15_0.png" />
</div>
</div>
<p>Generate 128 random noisy squares:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">points</span><span class="p">,</span> <span class="n">directions</span> <span class="o">=</span> <span class="n">generate_sequences</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Visualize the first five squares.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plot_data</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">directions</span><span class="p">,</span> <span class="n">n_rows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/seq2seq_19_0.png" src="../_images/seq2seq_19_0.png" />
</div>
</div>
</div>
<div class="section" id="encoder-decoder-architecture">
<h2><span class="section-number">4.4. </span>Encoder-Decoder Architecture<a class="headerlink" href="#encoder-decoder-architecture" title="Permalink to this headline">¶</a></h2>
<p>The encoder-decoder is a combination of two models: the <strong>encoder</strong> and the
<strong>decoder</strong>.</p>
<div class="section" id="encoder">
<h3><span class="section-number">4.4.1. </span>Encoder<a class="headerlink" href="#encoder" title="Permalink to this headline">¶</a></h3>
<p>The encoder’s goal is to generate a vector representation <span class="math notranslate nohighlight">\(\psi\)</span> of the source sequence, that is, to encode it.</p>
<p>An encoder can be any of the featuriser we have seen before, e.g. a Conv1D, an Elman RNN, a GRU, an LSTM or their stacked and bidirectional variances. Here we use a GRU, <span class="math notranslate nohighlight">\(\psi\)</span> is the hidden state of the last cell.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We kept the outputs of all cells in the <code class="docutils literal notranslate"><span class="pre">Encoder</span></code> code, to make the code more extendable to future “attention-based” models.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">basic_rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>        
        <span class="n">rnn_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basic_rnn</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">rnn_out</span> <span class="c1"># N, L, F</span>
</pre></div>
</div>
</div>
</div>
<p>A perfect square with two corners as source, and two coners target.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">full_seq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">source_seq</span> <span class="o">=</span> <span class="n">full_seq</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="c1"># first two corners</span>
<span class="n">target_seq</span> <span class="o">=</span> <span class="n">full_seq</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="c1"># last two corners</span>
</pre></div>
</div>
</div>
</div>
<p>We use the un-trained <code class="docutils literal notranslate"><span class="pre">Encoder</span></code> to encode the source sequence. If trained the output vector is expected to caputre the source seqence’s intrinsic positional thus directional information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">21</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">hidden_seq</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">source_seq</span><span class="p">)</span> <span class="c1"># output is N, L, F</span>
<span class="n">hidden_final</span> <span class="o">=</span> <span class="n">hidden_seq</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>   <span class="c1"># takes last hidden state</span>
<span class="n">hidden_final</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[ 0.3105, -0.5263]]], grad_fn=&lt;SliceBackward&gt;)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="decoder">
<h3><span class="section-number">4.4.2. </span>Decoder<a class="headerlink" href="#decoder" title="Permalink to this headline">¶</a></h3>
<p>The decoder’s goal is to generate the target sequence from an
initial representation, that is, to decode it.</p>
<p>Very often the decorder takes the encoder’s output of last cell, as its initial hidden state, and use last input the encoder as its first input, to generate a sequence of desired length. The output of each cell through a linear transformantion (<em>regression</em>) to obtain the output sequence of the decoder  So the encoder can be realised through an RNN or its variants  as well.</p>
<p>The code below uses a GRU layer as a decoder.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since we are generating numerical values that represent the coordinates of the corners, we are dealing with a regression problem. So in the later model training, we use MSE as loss function.</p>
</div>
<p><img alt="Encoder-Decoder" src="../_images/encoder_decoder.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">basic_rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">regression</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_seq</span><span class="p">):</span>
        <span class="c1"># We only need the final hidden state</span>
        <span class="n">hidden_final</span> <span class="o">=</span> <span class="n">hidden_seq</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span> <span class="c1"># N, 1, H</span>
        <span class="c1"># But we need to make it sequence-first</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden_final</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 1, N, H                      </span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># X is N, 1, F</span>
        <span class="n">batch_first_output</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basic_rnn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">)</span> 
        
        <span class="n">last_output</span> <span class="o">=</span> <span class="n">batch_first_output</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regression</span><span class="p">(</span><span class="n">last_output</span><span class="p">)</span>
        
        <span class="c1"># N, 1, F</span>
        <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span><span class="p">)</span>               
</pre></div>
</div>
</div>
</div>
<p>Decoder is often considered as a generator. Here the <code class="docutils literal notranslate"><span class="pre">decoder</span></code> is intialised with the last hidden state of the encoder first. The initial input is the last element of the source sequence. Then it takes the previous cell output as input, in a for loop, until it generate a specified number (<em>target sequence length</em>) of elements.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">21</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Initial hidden state will be encoder&#39;s final hidden state</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">hidden_seq</span><span class="p">)</span>
<span class="c1"># Initial data point is the last element of source sequence</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">source_seq</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>

<span class="n">target_len</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_len</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Hidden: </span><span class="si">{</span><span class="n">decoder</span><span class="o">.</span><span class="n">hidden</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>   <span class="c1"># Predicts coordinates</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Output: </span><span class="si">{</span><span class="n">out</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="c1"># Predicted coordinates are next step&#39;s inputs</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">out</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hidden: tensor([[[ 0.3105, -0.5263]]], grad_fn=&lt;PermuteBackward&gt;)
Output: tensor([[[-0.2339,  0.4702]]], grad_fn=&lt;ViewBackward&gt;)

Hidden: tensor([[[ 0.3913, -0.6853]]], grad_fn=&lt;StackBackward&gt;)
Output: tensor([[[-0.0226,  0.4628]]], grad_fn=&lt;ViewBackward&gt;)
</pre></div>
</div>
</div>
</div>
<div class="section" id="teacher-forcing">
<h4><span class="section-number">4.4.2.1. </span>Teacher Forcing<a class="headerlink" href="#teacher-forcing" title="Permalink to this headline">¶</a></h4>
<p>There is one problem with the approach above, an untrained model will
make really bad predictions, and these predictions will still be used as inputs for subsequent steps. This makes model training unnecessarily hard because the prediction error in one step is caused by both the (untrained) model and the prediction error in the previous step.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>We can use the actual target sequence instead!
This technique is called <strong>teacher forcing</strong>. We can ignore the predictions and use the real data from the target sequence instead.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initial hidden state will be encoder&#39;s final hidden state</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">hidden_seq</span><span class="p">)</span>
<span class="c1"># Initial data point is the last element of source sequence</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">source_seq</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>

<span class="n">target_len</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_len</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Hidden: </span><span class="si">{</span><span class="n">decoder</span><span class="o">.</span><span class="n">hidden</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="c1"># Predicts coordinates    </span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Output: </span><span class="si">{</span><span class="n">out</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="c1"># But completely ignores the predictions and uses real data instead</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">target_seq</span><span class="p">[:,</span> <span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hidden: tensor([[[ 0.3105, -0.5263]]], grad_fn=&lt;PermuteBackward&gt;)
Output: tensor([[[-0.2339,  0.4702]]], grad_fn=&lt;ViewBackward&gt;)

Hidden: tensor([[[ 0.3913, -0.6853]]], grad_fn=&lt;StackBackward&gt;)
Output: tensor([[[0.2265, 0.4529]]], grad_fn=&lt;ViewBackward&gt;)
</pre></div>
</div>
</div>
</div>
<p>Put the two cases together:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initial hidden state is encoder&#39;s final hidden state</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">hidden_seq</span><span class="p">)</span>
<span class="c1"># Initial data point is the last element of source sequence</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">source_seq</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>

<span class="n">teacher_forcing_prob</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">target_len</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_len</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Hidden: </span><span class="si">{</span><span class="n">decoder</span><span class="o">.</span><span class="n">hidden</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Output: </span><span class="si">{</span><span class="n">out</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="c1"># If it is teacher forcing</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">teacher_forcing_prob</span><span class="p">:</span>
        <span class="c1"># Takes the actual element</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">target_seq</span><span class="p">[:,</span> <span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Otherwise uses the last predicted output</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">out</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hidden: tensor([[[ 0.3105, -0.5263]]], grad_fn=&lt;PermuteBackward&gt;)
Output: tensor([[[-0.2339,  0.4702]]], grad_fn=&lt;ViewBackward&gt;)

Hidden: tensor([[[ 0.3913, -0.6853]]], grad_fn=&lt;StackBackward&gt;)
Output: tensor([[[-0.0226,  0.4628]]], grad_fn=&lt;ViewBackward&gt;)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="encoder-decoder">
<h3><span class="section-number">4.4.3. </span>Encoder + Decoder<a class="headerlink" href="#encoder-decoder" title="Permalink to this headline">¶</a></h3>
<p>We can assemble a <strong>boilerplate</strong> that integrates a encoder and a decoder. Given an encoder and a decoder model, the code below implements a forward method that splits the input into the source and target sequences, loops over the generation of the target sequence, and implements teacher forcing in training mode.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EncoderDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_len</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="n">teacher_forcing_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_len</span> <span class="o">=</span> <span class="n">input_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_len</span> <span class="o">=</span> <span class="n">target_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher_forcing_prob</span> <span class="o">=</span> <span class="n">teacher_forcing_prob</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="kc">None</span>
        
    <span class="k">def</span> <span class="nf">init_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        <span class="c1"># N, L (target), F</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> 
                              <span class="bp">self</span><span class="o">.</span><span class="n">target_len</span><span class="p">,</span> 
                              <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">n_features</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">store_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">out</span><span class="p">):</span>
        <span class="c1"># Stores the output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">out</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>               
        <span class="c1"># splits the data in source and target sequences</span>
        <span class="c1"># the target seq will be empty in testing mode</span>
        <span class="c1"># N, L, F</span>
        <span class="n">source_seq</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">input_len</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">target_seq</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_len</span><span class="p">:,</span> <span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_outputs</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>        
        
        <span class="c1"># Encoder expected N, L, F</span>
        <span class="n">hidden_seq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">source_seq</span><span class="p">)</span>
        <span class="c1"># Output is N, L, H</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">hidden_seq</span><span class="p">)</span>
        
        <span class="c1"># The last input of the encoder is also</span>
        <span class="c1"># the first input of the decoder</span>
        <span class="n">dec_inputs</span> <span class="o">=</span> <span class="n">source_seq</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>
        
        <span class="c1"># Generates as many outputs as the target length</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_len</span><span class="p">):</span>
            <span class="c1"># Output of decoder is N, 1, F</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_inputs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">store_output</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            
            <span class="n">prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">teacher_forcing_prob</span>
            <span class="c1"># In evaluation/test the target sequence is</span>
            <span class="c1"># unknown, so we cannot use teacher forcing</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="n">prob</span> <span class="o">=</span> <span class="mi">0</span>
                
            <span class="c1"># If it is teacher forcing</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">prob</span><span class="p">:</span>
                <span class="c1"># Takes the actual element</span>
                <span class="n">dec_inputs</span> <span class="o">=</span> <span class="n">target_seq</span><span class="p">[:,</span> <span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Otherwise uses the last predicted output</span>
                <span class="n">dec_inputs</span> <span class="o">=</span> <span class="n">out</span>
            
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encdec</span> <span class="o">=</span> <span class="n">EncoderDecoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_len</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">target_len</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">teacher_forcing_prob</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encdec</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">encdec</span><span class="p">(</span><span class="n">full_seq</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[-0.2339,  0.4702],
         [ 0.2265,  0.4529]]], grad_fn=&lt;CopySlices&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encdec</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">encdec</span><span class="p">(</span><span class="n">source_seq</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[-0.2339,  0.4702],
         [-0.0226,  0.4628]]], grad_fn=&lt;CopySlices&gt;)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-preparation">
<h3><span class="section-number">4.4.4. </span>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">¶</a></h3>
<p>The first two corners of the square <code class="docutils literal notranslate"><span class="pre">data[:,</span> <span class="pre">:2]</span></code> are the source sequences; the last two corners <code class="docutils literal notranslate"><span class="pre">data[:,</span> <span class="pre">2:]</span></code> are the target sequences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">points</span><span class="p">,</span> <span class="n">directions</span> <span class="o">=</span> <span class="n">generate_sequences</span><span class="p">()</span>
<span class="n">full_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">points</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">target_train</span> <span class="o">=</span> <span class="n">full_train</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_points</span><span class="p">,</span> <span class="n">test_directions</span> <span class="o">=</span> <span class="n">generate_sequences</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">19</span><span class="p">)</span>
<span class="n">full_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">points</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">source_test</span> <span class="o">=</span> <span class="n">full_test</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">target_test</span> <span class="o">=</span> <span class="n">full_test</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">full_train</span><span class="p">,</span> <span class="n">target_train</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">source_test</span><span class="p">,</span> <span class="n">target_test</span><span class="p">)</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-training-configuration">
<h3><span class="section-number">4.4.5. </span>Model Training &amp; Configuration<a class="headerlink" href="#model-training-configuration" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">23</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">EncoderDecoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_len</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">target_len</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">teacher_forcing_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sbs_seq</span> <span class="o">=</span> <span class="n">StepByStep</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">sbs_seq</span><span class="o">.</span><span class="n">set_loaders</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
<span class="n">sbs_seq</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">sbs_seq</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/seq2seq_53_0.png" src="../_images/seq2seq_53_0.png" />
</div>
</div>
</div>
<div class="section" id="visualizing-predictions">
<h3><span class="section-number">4.4.6. </span>Visualizing Predictions<a class="headerlink" href="#visualizing-predictions" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">sequence_pred</span><span class="p">(</span><span class="n">sbs_seq</span><span class="p">,</span> <span class="n">full_test</span><span class="p">,</span> <span class="n">test_directions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/seq2seq_55_0.png" src="../_images/seq2seq_55_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="bidirectional-lstm-as-an-encoder">
<h2><span class="section-number">4.5. </span>Bidirectional LSTM as an Encoder<a class="headerlink" href="#bidirectional-lstm-as-an-encoder" title="Permalink to this headline">¶</a></h2>
<p>We have been using the output of GRU above to exact the last hidden state as the representation vector <span class="math notranslate nohighlight">\(\psi\)</span> betwen the encoder and decoder. Note that despite the output and hidden state of a GRU cell is the same, we still used the output, rather than the hidden state. This is because the bidirectional variations outputs are hidden states are not the same. Recall that the overall output of the bidirectional RNN must have two elements:</p>
<ul class="simple">
<li><p>a concatenation side-by-side of both sequences of hidden states (input aligned)</p></li>
<li><p>the concatenation of final hidden states of both layers, the last of the forward layer is corresponding to the last element of the sequence, the last of the backward layer is corresponding to the first element of the sequence (i.e. not input aligned).</p></li>
</ul>
<p>See the figure below for clarification.</p>
<p><img alt="Bidirectional RNN" src="../_images/bidirect_rnn.png" /></p>
<p>For Sequence to Sequence model, we will need an input aligned output, so the code above largely should still work (the dimenionality changed though), but conceptually we need to be clear of what’s happening.</p>
<div class="admonition-your-turn admonition">
<p class="admonition-title">Your Turn</p>
<p>Change the code above to use BiLSTM as an encoder.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "executablebooks/jupyter-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./LSTM"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="gru_lstm_square.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">3. </span>The Square Model Using GRU and LSTM</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="Surname_Generation_Unconditioned.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">5. </span>Surname Generation - Unconditioned</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By A/Prof. Wei Liu<br/>
        
            &copy; Copyright UWA 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>