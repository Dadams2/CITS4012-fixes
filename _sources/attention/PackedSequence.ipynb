{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Packed Sequences \r\n",
    "======================\r\n",
    "Normally, a minibatch of *variable-­length* sequences is represented numerically as rows in a matrix of integers in which each sequence is left aligned and *zero­-padded* to accommodate the variable lengths. \r\n",
    "\r\n",
    "The `PackedSequence` data structure represents variable­-length sequences as an array by concatenating the data for the sequences at each time step, one after another, and knowing the number of sequences at each time step, as shown in the figure below.\r\n",
    "\r\n",
    "![Packed Sequences](../images/packed-sequence.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A matrix of padded sequences and its lengths are shown on the left. The padded matrix is the standard way of representing variable-­length sequences, by righ-­padding them with zeroes and stacking them as row vectors. \r\n",
    "\r\n",
    "In PyTorch, we can pack the padded sequences into a terser representation, the `PackedSequence`, shown on the right along with the batch sizes. This representation allows the GPU to step through the sequence by keeping track of how many sequences are in each time step (the batch sizes). Using the example above, \r\n",
    "- The longest sequence is 4, so the maximum time step is 4. \r\n",
    "- The first time step, we have three sequences (`a`,`e`, and `h`).\r\n",
    "- The second time step, we have two sequences (`b`, and `f`).\r\n",
    "- The third time step, we have two sequences (`c`, and `g`).\r\n",
    "- The final time step, we have one sequence (`d`)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def describe(x):\r\n",
    "    print(\"Type: {}\".format(x.type()))\r\n",
    "    print(\"Shape/size: {}\".format(x.shape))\r\n",
    "    print(\"Values: \\n{}\".format(x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## From padded to packed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "abcd_padded = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\r\n",
    "efg_padded = torch.tensor([5, 6, 7, 0], dtype=torch.float32)\r\n",
    "h_padded = torch.tensor([8, 0, 0, 0], dtype=torch.float32)\r\n",
    "\r\n",
    "padded_tensor = torch.stack([abcd_padded, efg_padded, h_padded])\r\n",
    "\r\n",
    "describe(padded_tensor)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4])\n",
      "Values: \n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 0.],\n",
      "        [8., 0., 0., 0.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "lengths = [4, 3, 1]\r\n",
    "packed_tensor = pack_padded_sequence(padded_tensor, lengths, \r\n",
    "                                     batch_first=True)\r\n",
    "packed_tensor"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1., 5., 8., 2., 6., 3., 7., 4.]), batch_sizes=tensor([3, 2, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## From packed to padded\r\n",
    "\r\n",
    "You can also turn packed sequence back to padded sequence"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "unpacked_tensor, unpacked_lengths = pad_packed_sequence(packed_tensor, batch_first=True)\r\n",
    "describe(unpacked_tensor)\r\n",
    "describe(unpacked_lengths)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4])\n",
      "Values: \n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 0.],\n",
      "        [8., 0., 0., 0.]])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3])\n",
      "Values: \n",
      "tensor([4, 3, 1])\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('cits4012': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "d990147e05fc0cc60dd3871899a6233eb6a5324c1885ded43d013dc915f7e535"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}