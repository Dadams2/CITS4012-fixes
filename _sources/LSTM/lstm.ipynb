{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Long Short Term Memories (LSTMs)\r\n",
    "================================="
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\r\n",
    "from torch.nn.utils import rnn as rnn_utils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM Cell"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "n_features = 2\r\n",
    "hidden_dim = 2\r\n",
    "\r\n",
    "torch.manual_seed(17)\r\n",
    "lstm_cell = nn.LSTMCell(input_size=n_features, hidden_size=hidden_dim)\r\n",
    "lstm_state = lstm_cell.state_dict()\r\n",
    "lstm_state"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih',\n",
       "              tensor([[-0.0930,  0.0497],\n",
       "                      [ 0.4670, -0.5319],\n",
       "                      [-0.6656,  0.0699],\n",
       "                      [-0.1662,  0.0654],\n",
       "                      [-0.0449, -0.6828],\n",
       "                      [-0.6769, -0.1889],\n",
       "                      [-0.4167, -0.4352],\n",
       "                      [-0.2060, -0.3989]])),\n",
       "             ('weight_hh',\n",
       "              tensor([[-0.7070, -0.5083],\n",
       "                      [ 0.1418,  0.0930],\n",
       "                      [-0.5729, -0.5700],\n",
       "                      [-0.1818, -0.6691],\n",
       "                      [-0.4316,  0.4019],\n",
       "                      [ 0.1222, -0.4647],\n",
       "                      [-0.5578,  0.4493],\n",
       "                      [-0.6800,  0.4422]])),\n",
       "             ('bias_ih',\n",
       "              tensor([-0.3559, -0.0279,  0.6553,  0.2918,  0.4007,  0.3262, -0.0778, -0.3002])),\n",
       "             ('bias_hh',\n",
       "              tensor([-0.3991, -0.3200,  0.3483, -0.2604, -0.1582,  0.5558,  0.5761, -0.3919]))])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def linear_layers(Wi, bi, Wh, bh):\r\n",
    "    hidden_dim, n_features = Wi.size()    \r\n",
    "    lin_input = nn.Linear(n_features, hidden_dim)\r\n",
    "    lin_input.load_state_dict({'weight': Wi, 'bias': bi})\r\n",
    "    lin_hidden = nn.Linear(hidden_dim, hidden_dim)\r\n",
    "    lin_hidden.load_state_dict({'weight': Wh, 'bias': bh})\r\n",
    "    return lin_hidden, lin_input"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "Wx, bx = lstm_state['weight_ih'], lstm_state['bias_ih']\r\n",
    "Wh, bh = lstm_state['weight_hh'], lstm_state['bias_hh']\r\n",
    "\r\n",
    "# Split weights and biases for data points\r\n",
    "Wxi, Wxf, Wxg, Wxo = Wx.split(hidden_dim, dim=0)\r\n",
    "bxi, bxf, bxg, bxo = bx.split(hidden_dim, dim=0)\r\n",
    "# Split weights and biases for hidden state\r\n",
    "Whi, Whf, Whg, Who = Wh.split(hidden_dim, dim=0)\r\n",
    "bhi, bhf, bhg, bho = bh.split(hidden_dim, dim=0)\r\n",
    "\r\n",
    "# Creates linear layers for the components\r\n",
    "i_hidden, i_input = linear_layers(Wxi, bxi, Whi, bhi) # input gate - green\r\n",
    "f_hidden, f_input = linear_layers(Wxf, bxf, Whf, bhf) # forget gate - red\r\n",
    "o_hidden, o_input = linear_layers(Wxo, bxo, Who, bho) # output gate - blue\r\n",
    "g_cell = nn.RNNCell(n_features, hidden_dim) # black\r\n",
    "g_cell.load_state_dict({'weight_ih': Wxg, 'bias_ih': bxg,\r\n",
    "                        'weight_hh': Whg, 'bias_hh': bhg})"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def forget_gate(h, x):\r\n",
    "    thf = f_hidden(h)\r\n",
    "    txf = f_input(x)\r\n",
    "    f = torch.sigmoid(thf + txf)\r\n",
    "    return f  # red\r\n",
    "    \r\n",
    "def output_gate(h, x):\r\n",
    "    tho = o_hidden(h)\r\n",
    "    txo = o_input(x)\r\n",
    "    o = torch.sigmoid(tho + txo)\r\n",
    "    return o  # blue\r\n",
    "\r\n",
    "def input_gate(h, x):\r\n",
    "    thi = i_hidden(h)\r\n",
    "    txi = i_input(x)\r\n",
    "    i = torch.sigmoid(thi + txi)\r\n",
    "    return i  # green"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def generate_sequences(n=128, variable_len=False, seed=13):\r\n",
    "    basic_corners = np.array([[-1, -1], [-1, 1], [1, 1], [1, -1]])\r\n",
    "    np.random.seed(seed)\r\n",
    "    bases = np.random.randint(4, size=n)\r\n",
    "    if variable_len:\r\n",
    "        lengths = np.random.randint(3, size=n) + 2\r\n",
    "    else:\r\n",
    "        lengths = [4] * n\r\n",
    "    directions = np.random.randint(2, size=n)\r\n",
    "    points = [basic_corners[[(b + i) % 4 for i in range(4)]][slice(None, None, d*2-1)][:l] + np.random.randn(l, 2) * 0.1 for b, d, l in zip(bases, directions, lengths)]\r\n",
    "    return points, directions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "points, directions = generate_sequences(n=128, seed=13)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "initial_hidden = torch.zeros(1, hidden_dim)\r\n",
    "initial_cell = torch.zeros(1, hidden_dim)\r\n",
    "\r\n",
    "X = torch.as_tensor(points[0]).float()\r\n",
    "first_corner = X[0:1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "g = g_cell(first_corner)\r\n",
    "i = input_gate(initial_hidden, first_corner)\r\n",
    "gated_input = g * i\r\n",
    "gated_input"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.1340, -0.0004]], grad_fn=<MulBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "f = forget_gate(initial_hidden, first_corner)\r\n",
    "gated_cell = initial_cell * f\r\n",
    "gated_cell"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0.]], grad_fn=<MulBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "c_prime = gated_cell + gated_input\r\n",
    "c_prime"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.1340, -0.0004]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "o = output_gate(initial_hidden, first_corner)\r\n",
    "h_prime = o * torch.tanh(c_prime)\r\n",
    "h_prime\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-5.4936e-02, -8.3810e-05]], grad_fn=<MulBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "(h_prime, c_prime)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[-5.4936e-02, -8.3810e-05]], grad_fn=<MulBackward0>),\n",
       " tensor([[-0.1340, -0.0004]], grad_fn=<AddBackward0>))"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "lstm_cell(first_corner)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[-5.4936e-02, -8.3810e-05]], grad_fn=<MulBackward0>),\n",
       " tensor([[-0.1340, -0.0004]], grad_fn=<AddBackward0>))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('cits4012': conda)"
  },
  "interpreter": {
   "hash": "d990147e05fc0cc60dd3871899a6233eb6a5324c1885ded43d013dc915f7e535"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}