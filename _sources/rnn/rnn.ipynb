{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Recurrent Neural Networks - Introduction\r\n",
    "========================================\r\n",
    "\r\n",
    "In this notebook, we will look at the basics of how to use `nn.RNNCell` and `nn.RNN` to create RNN Cells and RNN layers, and illustrate the important tensor shape expectation of RNN. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNN Cell\r\n",
    "\r\n",
    "Given an input feature $n$, and a hidden dimension $d$, if the transformed dimension is m, then the dimensionality of $W_{ih}$ should be $m \\times n$, and the $W_{hh}$ should be $m \\times d$.\r\n",
    "\r\n",
    "The following code randomly initialised a ($2\\times 2$) hidden to hidden matrix, and a ($2\\times 2$) input to hidden matrix. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "n_features = 2\r\n",
    "hidden_dim = 2\r\n",
    "\r\n",
    "torch.manual_seed(19)\r\n",
    "rnn_cell = nn.RNNCell(input_size=n_features, hidden_size=hidden_dim)\r\n",
    "rnn_cell.state_dict()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih',\n",
       "              tensor([[ 0.6627, -0.4245],\n",
       "                      [ 0.5373,  0.2294]])),\n",
       "             ('weight_hh',\n",
       "              tensor([[-0.4015, -0.5385],\n",
       "                      [-0.1956, -0.6835]])),\n",
       "             ('bias_ih', tensor([0.4954, 0.6533])),\n",
       "             ('bias_hh', tensor([-0.3565, -0.2904]))])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    ":::{admonition} Your Turn\r\n",
    "Modify the input feature and hidden dimension, to observe how the weight matrices change. \r\n",
    ":::"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNN Layer\r\n",
    "\r\n",
    "RNN cell requires us manually feed the cell hidden layer as one of the two inputs (previous hidden state and current input) to the same RNN cell in a for loop. See the `forward()` method in the [ElmanRNN model class](https://weiliu2k.github.io/CITS4012/rnn/Surname_Classification.html#model) as an example. Luckily PyTorch has a `nn.RNN()` function that looks after this recurrent behaviour for us. \r\n",
    "\r\n",
    "The example below creates the same set of weights, but with `l0` suffix for the weight matrix keys, to indicate these weights are the first layer of RNN."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "n_features = 2\r\n",
    "hidden_dim = 2\r\n",
    "\r\n",
    "torch.manual_seed(19)\r\n",
    "rnn = nn.RNN(input_size=n_features, hidden_size=hidden_dim)\r\n",
    "rnn.state_dict()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0',\n",
       "              tensor([[ 0.6627, -0.4245],\n",
       "                      [ 0.5373,  0.2294]])),\n",
       "             ('weight_hh_l0',\n",
       "              tensor([[-0.4015, -0.5385],\n",
       "                      [-0.1956, -0.6835]])),\n",
       "             ('bias_ih_l0', tensor([0.4954, 0.6533])),\n",
       "             ('bias_hh_l0', tensor([-0.3565, -0.2904]))])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sequence-first shape default in RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate some synthetic data\r\n",
    "\r\n",
    "The code below generate random sequences of four points (`points` e.g. A, B, C, D) Each point has two values, which can be think of a data point in a 2D space. The sequence are points in sequence that are ordered either clock-wise or counter-wise (`direction`). This is a simplified version of sentences, \r\n",
    "\r\n",
    "- sentences are sequences (of words);\r\n",
    "- the order or direction of the above sequence is analogus to classes, e.g. sentiment or news categories\r\n",
    "- words are elements in the sequence, representing as vectors with dimensions. \r\n",
    "\r\n",
    "The example data points has a feature space of two dimensions, so they can be easily visualised using a x-y Cartesian coordinate system, whereas words may be in 50, 100, 300 etc. dimensions depending on the embedding methods. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "def generate_sequences(n=128, variable_len=False, seed=13):\r\n",
    "    basic_corners = np.array([[-1, -1], [-1, 1], [1, 1], [1, -1]])\r\n",
    "    np.random.seed(seed)\r\n",
    "    bases = np.random.randint(4, size=n)\r\n",
    "    if variable_len:\r\n",
    "        lengths = np.random.randint(3, size=n) + 2\r\n",
    "    else:\r\n",
    "        lengths = [4] * n\r\n",
    "    directions = np.random.randint(2, size=n)\r\n",
    "    points = [basic_corners[[(b + i) % 4 for i in range(4)]][slice(None, None, d*2-1)][:l] + np.random.randn(l, 2) * 0.1 for b, d, l in zip(bases, directions, lengths)]\r\n",
    "    return points, directions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "points, directions = generate_sequences(n=128, seed=13)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Batch-first tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now take three (N=3) sequences, each sequence has four data points (L=4), with two features (F=2) representing each data point. This is an example of batch-first input tensor (N,L,F), as shown in the example below.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "batch = torch.as_tensor(points[:3]).float()\r\n",
    "batch.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How to use RNN with correctly shaped tensors\r\n",
    "\r\n",
    "However, RNN uses *sequence-first* by default (L,N,F), we need to make our tensor **RNN friendly**. Two options:\r\n",
    "\r\n",
    "1. We could explicitly change the shape of the batch using `permute()` to flip the first two dimensions.\r\n",
    "2. We could use the `batch_first` argument in the RNN layer construction. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Option 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# From a batch-first tensor to sequence-first\r\n",
    "permuted_batch = batch.permute(1, 0, 2)\r\n",
    "permuted_batch.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the data is in an \"RNN-friendly\" shape and we can run it through a regular RNN to get two sequence-first tensors back:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "torch.manual_seed(19)\r\n",
    "rnn = nn.RNN(input_size=n_features, hidden_size=hidden_dim)\r\n",
    "out, final_hidden = rnn(permuted_batch)\r\n",
    "out.shape, final_hidden.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 2]), torch.Size([1, 3, 2]))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we're done with the RNN we can turn the data back to our familiar batchfirst\r\n",
    "shape:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "batch_hidden = final_hidden.permute(1, 0, 2)\r\n",
    "batch.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    ":::{admonition} Your Turn\r\n",
    "In the code above, the hidden state dimension (`hidden_dim`) happens to be the same as the number of input features (`n_features`), which is 2. These two do not have to agree. For example, the word embedding dimension can be 100 (e.g. `n_features=100`), the hidden dimension can be 50 (`hidden_dim=50`). Change these two parameters to observe the shape change and get familar with the sequence-first and batch-first tensor shapes.\r\n",
    ":::"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Option 2\r\n",
    "\r\n",
    "Option 1 is a lot of work to keep track of, we can instead set RNN's `batch_first` argument to True so we can use the batch above without any modifications.\r\n",
    "\r\n",
    ":::{warning}\r\n",
    "But you get these two distinct shapes as a result: batch-first (N,L,H) for the\r\n",
    "output and sequence-first (1,N,H) for the final hidden state.\r\n",
    ":::\r\n",
    "\r\n",
    "On the one hand, this can lead to confusion. On the other hand, most of the time we\r\n",
    "would not be handling the hidden state, and we will handle the *batch-first* output instead.\r\n",
    "So, we can stick with batch-first for now and, when it comes the time we have to\r\n",
    "handle the hidden state, we will highlight the difference in shapes once again."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "torch.manual_seed(19)\r\n",
    "rnn_batch_first = nn.RNN(input_size=n_features, hidden_size=hidden_dim, batch_first=True)\r\n",
    "out, final_hidden = rnn_batch_first(batch)\r\n",
    "out.shape, final_hidden.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 2]), torch.Size([1, 3, 2]))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    ":::{note}\r\n",
    "For simple RNNs, the last element of the output IS the final hidden state!\r\n",
    ":::"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "out = out.permute(1,0,2)\r\n",
    "(out[-1] == final_hidden).all()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    ":::{admonition} Summary\r\n",
    "The RNN's default behavior is to handle tensors having the shape (L,N,H) for hidden states and (L,N,F) for sequences of data points. \r\n",
    "\r\n",
    "Datasets and data loaders, unless customized otherwise, will produce data points in the shape (N,L,F).\r\n",
    "\r\n",
    "To address this difference, we'll be using OPTION 2 the `batch_first` argument to turn both inputs and outputs into this familiar batch-first shape. But be aware of the shape difference between hidden state and output state. In other words, with `batch_first` argument to be true, we have input and output \"batch-first\", but the hidden states are still \"sequence-first\".\r\n",
    ":::"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stacked RNN with Two Layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "torch.manual_seed(19)\r\n",
    "rnn_stacked = nn.RNN(input_size=2, hidden_size=2,\r\n",
    "        num_layers=2, batch_first=True)\r\n",
    "state = rnn_stacked.state_dict()\r\n",
    "state"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0',\n",
       "              tensor([[ 0.6627, -0.4245],\n",
       "                      [ 0.5373,  0.2294]])),\n",
       "             ('weight_hh_l0',\n",
       "              tensor([[-0.4015, -0.5385],\n",
       "                      [-0.1956, -0.6835]])),\n",
       "             ('bias_ih_l0', tensor([0.4954, 0.6533])),\n",
       "             ('bias_hh_l0', tensor([-0.3565, -0.2904])),\n",
       "             ('weight_ih_l1',\n",
       "              tensor([[-0.6701, -0.5811],\n",
       "                      [-0.0170, -0.5856]])),\n",
       "             ('weight_hh_l1',\n",
       "              tensor([[ 0.1159, -0.6978],\n",
       "                      [ 0.3241, -0.0983]])),\n",
       "             ('bias_ih_l1', tensor([-0.3163, -0.2153])),\n",
       "             ('bias_hh_l1', tensor([ 0.0722, -0.3242]))])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manually Stacking Two RNNs\r\n",
    "\r\n",
    "Let's replicate the above with two RNNs, \"manually\" stacked together."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "list(state.items())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('weight_ih_l0',\n",
       "  tensor([[ 0.6627, -0.4245],\n",
       "          [ 0.5373,  0.2294]])),\n",
       " ('weight_hh_l0',\n",
       "  tensor([[-0.4015, -0.5385],\n",
       "          [-0.1956, -0.6835]])),\n",
       " ('bias_ih_l0', tensor([0.4954, 0.6533])),\n",
       " ('bias_hh_l0', tensor([-0.3565, -0.2904])),\n",
       " ('weight_ih_l1',\n",
       "  tensor([[-0.6701, -0.5811],\n",
       "          [-0.0170, -0.5856]])),\n",
       " ('weight_hh_l1',\n",
       "  tensor([[ 0.1159, -0.6978],\n",
       "          [ 0.3241, -0.0983]])),\n",
       " ('bias_ih_l1', tensor([-0.3163, -0.2153])),\n",
       " ('bias_hh_l1', tensor([ 0.0722, -0.3242]))]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    ":::{admonition} Your Turn\r\n",
    "Give a string `k`, what does `k[:-1]` do?\r\n",
    "::: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "str = 'test'\r\n",
    "str[:-2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'te'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "dict([(k[:-1]+'0', v) for k, v in list(state.items())[4:]])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'weight_ih_l0': tensor([[-0.6701, -0.5811],\n",
       "         [-0.0170, -0.5856]]),\n",
       " 'weight_hh_l0': tensor([[ 0.1159, -0.6978],\n",
       "         [ 0.3241, -0.0983]]),\n",
       " 'bias_ih_l0': tensor([-0.3163, -0.2153]),\n",
       " 'bias_hh_l0': tensor([ 0.0722, -0.3242])}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Create two RNNs\r\n",
    "rnn_layer0 = nn.RNN(input_size=2, hidden_size=2, batch_first=True)\r\n",
    "rnn_layer1 = nn.RNN(input_size=2, hidden_size=2, batch_first=True)\r\n",
    "# Load the same weights from above\r\n",
    "rnn_layer0.load_state_dict(dict(list(state.items())[:4]))\r\n",
    "# Note the layer label (keys) need to change\r\n",
    "rnn_layer1.load_state_dict(dict([(k[:-1]+'0', v) for k, v in list(state.items())[4:]]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 0: A batch sequence from the sample (N=1, L=4, F=2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "x = torch.as_tensor(points[0:1]).float()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 1: Feed the input to the first RNN layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "out0, h0 = rnn_layer0(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 2: Feed the output of the first layer to the second RNN layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "out1, h1 = rnn_layer1(out0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The overall output of the stacked RNN must have two elements as well:\r\n",
    "- a sequence of hidden states, those produced by the last layer (`out1`)\r\n",
    "- the concatenation of final hidden states of all layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "out1, torch.cat([h0, h1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[-0.7533, -0.7711],\n",
       "          [-0.0566, -0.5960],\n",
       "          [ 0.4324, -0.2908],\n",
       "          [ 0.1563, -0.5152]]], grad_fn=<TransposeBackward1>),\n",
       " tensor([[[-0.5297,  0.3551]],\n",
       " \n",
       "         [[ 0.1563, -0.5152]]], grad_fn=<CatBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This should be the same as running a stacked RNN, as shown below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "out, hidden = rnn_stacked(x)\r\n",
    "out, hidden"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[-0.7533, -0.7711],\n",
       "          [-0.0566, -0.5960],\n",
       "          [ 0.4324, -0.2908],\n",
       "          [ 0.1563, -0.5152]]], grad_fn=<TransposeBackward1>),\n",
       " tensor([[[-0.5297,  0.3551]],\n",
       " \n",
       "         [[ 0.1563, -0.5152]]], grad_fn=<StackBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    ":::{important}\r\n",
    "For stacked RNNs, the last element of the output is the final hidden state of the LAST LAYER!\r\n",
    ":::\r\n",
    "But, since we’re using a batch_first layer, we need to permute the hidden state’s\r\n",
    "dimensions to batch-first as well:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "(out[:, -1] == hidden.permute(1, 0, 2)[:, -1]).all()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bidirectional RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "torch.manual_seed(19)\r\n",
    "rnn_bidirect = nn.RNN(input_size=2, hidden_size=2,\r\n",
    "            bidirectional=True, batch_first=True)\r\n",
    "state = rnn_bidirect.state_dict()\r\n",
    "state"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0',\n",
       "              tensor([[ 0.6627, -0.4245],\n",
       "                      [ 0.5373,  0.2294]])),\n",
       "             ('weight_hh_l0',\n",
       "              tensor([[-0.4015, -0.5385],\n",
       "                      [-0.1956, -0.6835]])),\n",
       "             ('bias_ih_l0', tensor([0.4954, 0.6533])),\n",
       "             ('bias_hh_l0', tensor([-0.3565, -0.2904])),\n",
       "             ('weight_ih_l0_reverse',\n",
       "              tensor([[-0.6701, -0.5811],\n",
       "                      [-0.0170, -0.5856]])),\n",
       "             ('weight_hh_l0_reverse',\n",
       "              tensor([[ 0.1159, -0.6978],\n",
       "                      [ 0.3241, -0.0983]])),\n",
       "             ('bias_ih_l0_reverse', tensor([-0.3163, -0.2153])),\n",
       "             ('bias_hh_l0_reverse', tensor([ 0.0722, -0.3242]))])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manually Created Bidirectional RNN\r\n",
    "\r\n",
    "Once again, we can create two simple RNNs, and use the weights and biases above to\r\n",
    "set their weights accordingly. Each RNN will behave as one of the layers from the\r\n",
    "bidirectional one:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "rnn_forward = nn.RNN(input_size=2, hidden_size=2, batch_first=True)\r\n",
    "rnn_reverse = nn.RNN(input_size=2, hidden_size=2, batch_first=True)\r\n",
    "rnn_forward.load_state_dict(dict(list(state.items())[:4]))\r\n",
    "rnn_reverse.load_state_dict(dict([(k[:-8], v) for k, v in list(state.items())[4:]]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 0: A batch sequence and its reverse"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "x = torch.as_tensor(points[0:1]).float()\r\n",
    "print(x)\r\n",
    "x_rev = torch.flip(x, dims=[1]) #N, L, F\r\n",
    "print(x_rev)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 1.0349,  0.9661],\n",
      "         [ 0.8055, -0.9169],\n",
      "         [-0.8251, -0.9499],\n",
      "         [-0.8670,  0.9342]]])\n",
      "tensor([[[-0.8670,  0.9342],\n",
      "         [-0.8251, -0.9499],\n",
      "         [ 0.8055, -0.9169],\n",
      "         [ 1.0349,  0.9661]]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 1: Feed each RNN with its corresponding sequence\r\n",
    "\r\n",
    "Since there is no dependency between the two layers, we just need to feed each\r\n",
    "layer its corresponding sequence (regular and reversed) and remember to reverse\r\n",
    "back the sequence of hidden states."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "out, h = rnn_forward(x)\r\n",
    "out_rev, h_rev = rnn_reverse(x_rev)\r\n",
    "out_rev_back = torch.flip(out_rev, dims=[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Tidy up the output\r\n",
    "\r\n",
    "The overall output of the bidirectional RNN must have two elements as well:\r\n",
    "- a concatenation side-by-side of both sequences of hidden states (out and\r\n",
    "out_rev_back)\r\n",
    "- the concatenation of final hidden states of both layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "out"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.3924,  0.8146],\n",
       "         [ 0.4347, -0.0481],\n",
       "         [-0.1521, -0.3367],\n",
       "         [-0.5297,  0.3551]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "out_rev_back"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-0.9355, -0.8353],\n",
       "         [-0.1766,  0.2596],\n",
       "         [ 0.8829,  0.0425],\n",
       "         [-0.2032, -0.7901]]], grad_fn=<FlipBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "torch.cat([out, out_rev_back], dim=2), torch.cat([h, h_rev])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3924,  0.8146, -0.9355, -0.8353],\n",
       "          [ 0.4347, -0.0481, -0.1766,  0.2596],\n",
       "          [-0.1521, -0.3367,  0.8829,  0.0425],\n",
       "          [-0.5297,  0.3551, -0.2032, -0.7901]]], grad_fn=<CatBackward>),\n",
       " tensor([[[-0.5297,  0.3551]],\n",
       " \n",
       "         [[-0.9355, -0.8353]]], grad_fn=<CatBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Double check the results with the bi-directional RNN itself"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "out, hidden = rnn_bidirect(x)\r\n",
    "out, hidden"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3924,  0.8146, -0.9355, -0.8353],\n",
       "          [ 0.4347, -0.0481, -0.1766,  0.2596],\n",
       "          [-0.1521, -0.3367,  0.8829,  0.0425],\n",
       "          [-0.5297,  0.3551, -0.2032, -0.7901]]], grad_fn=<TransposeBackward1>),\n",
       " tensor([[[-0.5297,  0.3551]],\n",
       " \n",
       "         [[-0.9355, -0.8353]]], grad_fn=<StackBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    ":::{important}\r\n",
    "For bidirectional RNNs, the last element of the output **ISN'T** the final hidden state! Once again, since we're using a `batch_first` layer, we need to permute the hidden state's dimensions to batch-first as well:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "out[:, -1] == hidden.permute(1, 0, 2).view(1, -1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False, False]])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bidirectional RNNs are different because the final hidden state corresponds to the last element in the sequence for the forward layer and to the first element in the sequence for the reverse\r\n",
    "layer. The output, on the other hand, is aligned to sequence, hence the difference."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('cits4012': conda)"
  },
  "interpreter": {
   "hash": "d990147e05fc0cc60dd3871899a6233eb6a5324c1885ded43d013dc915f7e535"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}